{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2BUzIVEWdIVq",
        "outputId": "4d16b18b-16f4-4b4c-96c6-daaced7b8ad4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R-squared: 0.30889534294031173\n",
            "Degree: 2, R-squared: 0.2631555367646886\n",
            "Degree: 3, R-squared: 0.2647703667639638\n",
            "Degree: 4, R-squared: 0.30715450908399583\n",
            "Degree: 5, R-squared: 0.3073102126494792\n",
            "Degree: 6, R-squared: 0.3082438301499719\n",
            "Degree: 7, R-squared: 0.30826364061334766\n",
            "Degree: 8, R-squared: 0.30875144422365214\n",
            "Degree: 9, R-squared: 0.30882876575252854\n",
            "Degree: 10, R-squared: 0.30889534294031173\n",
            "\n",
            "Best degree: 10, Best R-squared: 0.30889534294031173\n",
            "target label:[-9.72209577e-11 -4.38856090e-11 -9.61107756e-09 -1.14823627e-08\n",
            " -6.69917737e-09  5.64296549e-09  5.29108200e-09  3.54160718e-10\n",
            "  3.21516219e-10  6.75560880e-10 -2.52357635e-09 -6.88362406e-09\n",
            "  8.81116498e-09 -7.82275597e-09  4.43537560e-10  4.86895231e-08\n",
            " -1.08004617e-08 -1.00470792e-08  3.45631727e-09 -1.04631527e-11\n",
            "  1.07529626e-08  3.07318930e-10  9.06802230e-10  5.68885603e-09\n",
            "  2.01711282e-10 -1.11005793e-08  3.14067510e-09 -5.45724277e-09\n",
            "  2.15448619e-09  2.22491784e-09 -4.87148229e-10  2.26989330e-09\n",
            "  1.15994886e-08 -2.35564297e-09  1.19805895e-08  1.45770970e-09\n",
            "  3.24028878e-09 -2.33019793e-09 -8.87843096e-09  2.18298129e-08\n",
            "  2.63632552e-08 -1.87170812e-09 -1.16721064e-09 -9.83601011e-10\n",
            "  5.72845416e-09 -6.00967118e-09  1.93079150e-08  2.92512196e-10\n",
            "  1.97992139e-09  7.87711488e-10], predictions: [-7.89584285e-09 -3.17778007e-09  8.79499620e-09 ...  8.98963936e-09\n",
            "  7.77939811e-09 -4.25971653e-10]\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "import copy, math\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "df = pd.read_excel('polynomial_regression_train.xlsx')\n",
        "df1 = pd.read_csv('polynomial_regression_test.csv')\n",
        "\n",
        "\n",
        "X_train = df.iloc[1:44000,1:6]\n",
        "y_train = df.iloc[1:44000,6]\n",
        "\n",
        "X_CV = df.iloc[44001:47000,1:6]\n",
        "y_CV = df.iloc[44001:47000,6].values\n",
        "\n",
        "\n",
        "class PolynomialRegression:\n",
        "    def __init__(self, degree):\n",
        "        self.degree = degree\n",
        "        self.weights = None\n",
        "        self.num_features = None\n",
        "\n",
        "    def generate_polynomial_features(self, X):\n",
        "        \"\"\"Generates polynomial features up to the specified degree.\"\"\"\n",
        "        n_samples, n_features = X.shape\n",
        "        X_poly = np.ones((n_samples, 1))  # Initialize with a column of 1s (for the intercept)\n",
        "        for i in range(1, self.degree + 1):\n",
        "            X_poly = np.concatenate((X_poly, X**i), axis=1)\n",
        "        if self.num_features is not None:\n",
        "           if X_poly.shape[1] < self.num_features:\n",
        "               padding = np.zeros((X_poly.shape[0], self.num_features - X_poly.shape[1]))\n",
        "               X_poly = np.concatenate((X_poly, padding), axis=1)\n",
        "           elif X_poly.shape[1] > self.num_features:\n",
        "               X_poly = X_poly[:, :self.num_features]\n",
        "        return X_poly\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        \"\"\"Fits the model using the provided data.\"\"\"\n",
        "        X_poly = self.generate_polynomial_features(X)\n",
        "        self.weights = np.linalg.solve(X_poly.T @ X_poly, X_poly.T @ y)  # Normal equation\n",
        "        self.num_features = X_poly.shape[1]\n",
        "    def predict(self, X):\n",
        "        \"\"\"Predicts target values for new data.\"\"\"\n",
        "        X_poly = self.generate_polynomial_features(X)\n",
        "        return X_poly @ self.weights\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# ... (your existing data loading and class definition) ...\n",
        "\n",
        "def r_squared(y, y_hat):\n",
        "    \"\"\"\n",
        "    Calculates the R-squared (coefficient of determination) score.\n",
        "\n",
        "    Args:\n",
        "        y (ndarray): The actual target values.\n",
        "        y_hat (ndarray): The predicted target values.\n",
        "\n",
        "    Returns:\n",
        "        float: The R-squared score.\n",
        "    \"\"\"\n",
        "    y_bar = y.mean()  # Calculate the mean of the actual values\n",
        "    ss_tot = ((y - y_bar)**2).sum()  # Total sum of squares\n",
        "    ss_res = ((y_bar - y_hat)**2).sum()  # Residual sum of squares\n",
        "    return  (ss_res / ss_tot)\n",
        "\n",
        "y_pred = model.predict(X_CV)\n",
        "r2 = r_squared(y_CV, y_pred)\n",
        "print(f\"R-squared: {r2}\")\n",
        "\n",
        "# Experiment with different degrees\n",
        "degrees_to_try = [2, 3, 4, 5, 6,7,8,9,10]  # Try degrees from 2 to 6\n",
        "best_r2 = -1  # Initialize with a low value\n",
        "best_degree = None\n",
        "\n",
        "for degree in degrees_to_try:\n",
        "    model = PolynomialRegression(degree=degree)\n",
        "    model.fit(X_train, y_train)\n",
        "    predictions = model.predict(X_CV)\n",
        "    r2_score = r_squared(y_CV, predictions)  # Assuming you have the r_squared function defined\n",
        "\n",
        "    print(f\"Degree: {degree}, R-squared: {r2_score}\")\n",
        "\n",
        "    if r2_score > best_r2:\n",
        "        best_r2 = r2_score\n",
        "        best_degree = degree\n",
        "\n",
        "print(f\"\\nBest degree: {best_degree}, Best R-squared: {best_r2}\")\n",
        "\n",
        "# Use the best degree for your final model\n",
        "final_model = PolynomialRegression(degree=best_degree)\n",
        "final_model.fit(X_train, y_train)\n",
        "\n",
        "# ... (rest of your code) ...\n",
        "\n",
        "\n",
        "\n",
        "print(f\"target label:{y_CV.T[:50]}, predictions: {predictions}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def r_squared(y, y_hat):\n",
        "    \"\"\"\n",
        "    Calculates the R-squared (coefficient of determination) score.\n",
        "\n",
        "    Args:\n",
        "        y (ndarray): The actual target values.\n",
        "        y_hat (ndarray): The predicted target values.\n",
        "\n",
        "    Returns:\n",
        "        float: The R-squared score.\n",
        "    \"\"\"\n",
        "    y_bar = y.mean()  # Calculate the mean of the actual values\n",
        "    ss_tot = ((y - y_bar)**2).sum()  # Total sum of squares\n",
        "    ss_res = ((y_bar - y_hat)**2).sum()  # Residual sum of squares\n",
        "    return  (ss_res / ss_tot)\n",
        "\n",
        "y_pred = model.predict(X_CV)\n",
        "r2 = r_squared(y_CV, y_pred)\n",
        "print(f\"R-squared: {r2}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ktBRWYUXkPHY",
        "outputId": "537cbd5b-f4c6-4382-b124-060131b6e164"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R-squared: 0.30889534294031173\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# test set prediction\n",
        "\n",
        "df1 = pd.read_csv('polynomial_regression_test.csv')\n",
        "X_test = df1.iloc[:,1:-1]\n",
        "y_pred_test = model.predict(X_test)\n",
        "print(y_pred_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3oI9zBBKP-ci",
        "outputId": "90888435-cd9b-4465-d588-a81cd4e53e7c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[-3.13749148e-07 -7.52508232e-08 -1.43409853e-09 ...  2.58027056e-08\n",
            "  3.51988261e-09 -9.38809097e-10]\n"
          ]
        }
      ]
    }
  ]
}